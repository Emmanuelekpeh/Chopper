{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60473da9",
   "metadata": {},
   "source": [
    "# Chopper Audio Generation Collaborative Notebook\n",
    "\n",
    "This notebook allows for collaborative training and inference with the Chopper audio generation project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a04f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (your friend will do this)\n",
    "!git clone https://github.com/Emmanuelekpeh/Chopper.git\n",
    "%cd Chopper\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "!pip install torch librosa soundfile matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b216b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Import project modules\n",
    "from core.transformer_generator import TransformerSampleGenerator\n",
    "from core.improved_generator import ImprovedSampleGenerator\n",
    "from core.processing_pipeline import ProcessingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407d9c6",
   "metadata": {},
   "source": [
    "## Training Section\n",
    "\n",
    "Upload audio samples or download from sources, then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to upload samples\n",
    "from google.colab import files\n",
    "\n",
    "def upload_samples():\n",
    "    uploaded = files.upload()\n",
    "    sample_paths = []\n",
    "    for filename in uploaded.keys():\n",
    "        path = f'data/raw/{filename}'\n",
    "        os.makedirs('data/raw', exist_ok=True)\n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(uploaded[filename])\n",
    "        sample_paths.append(path)\n",
    "    return sample_paths\n",
    "\n",
    "# Uncomment to upload your samples\n",
    "# sample_paths = upload_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or download samples from Looperman or Splice\n",
    "from core.playwright_scraper import PlaywrightScraper\n",
    "from core.splice_scraper import SpliceLoopScraper\n",
    "\n",
    "def download_looperman(query=\"drum loop\", pages=2):\n",
    "    os.makedirs('data/raw', exist_ok=True)\n",
    "    scraper = PlaywrightScraper(download_dir=\"data/raw\")\n",
    "    samples = scraper.bulk_download(query, pages=pages)\n",
    "    print(f\"Downloaded {len(samples)} samples from Looperman\")\n",
    "    return samples\n",
    "\n",
    "# Uncomment to download samples\n",
    "# sample_paths = download_looperman(query=\"drum loop\", pages=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c17449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the samples\n",
    "def process_samples(sample_paths):\n",
    "    pipeline = ProcessingPipeline()\n",
    "    results = pipeline.process_batch(sample_paths)\n",
    "    metadata = pipeline.create_dataset_metadata(results)\n",
    "    print(f\"Processed {metadata['successful']} files successfully\")\n",
    "    print(f\"Created {metadata['total_segments']} segments\")\n",
    "    return metadata\n",
    "\n",
    "# Uncomment to process your samples\n",
    "# metadata = process_samples(sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Transformer model\n",
    "def train_transformer_model(dataset_paths, epochs=50, batch_size=16, save_path='models/transformer_gan.pt'):\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    generator = TransformerSampleGenerator()\n",
    "    generator.train(dataset_paths, epochs=epochs, batch_size=batch_size, save_path=save_path)\n",
    "    return generator\n",
    "\n",
    "# Uncomment to train with your processed samples\n",
    "# generator = train_transformer_model(metadata['segment_paths'], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b7d58",
   "metadata": {},
   "source": [
    "## Inference Section\n",
    "\n",
    "Generate new audio samples using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model and generate samples\n",
    "def generate_samples(model_path='models/transformer_gan.pt', count=3):\n",
    "    generator = TransformerSampleGenerator(model_path=model_path)\n",
    "    \n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    for i in range(count):\n",
    "        output_path = f'output/generated_sample_{i}.wav'\n",
    "        generator.generate_and_save_audio(output_path)\n",
    "        \n",
    "        # Display and play the audio\n",
    "        waveform, sr = librosa.load(output_path, sr=None)\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        plt.plot(waveform)\n",
    "        plt.title(f\"Generated Sample {i}\")\n",
    "        plt.show()\n",
    "        \n",
    "        display(Audio(output_path))\n",
    "    \n",
    "    return [f'output/generated_sample_{i}.wav' for i in range(count)]\n",
    "\n",
    "# Uncomment to generate samples\n",
    "# sample_files = generate_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac0140",
   "metadata": {},
   "source": [
    "## Model Saving & Sharing\n",
    "\n",
    "Save your model to Google Drive or push it back to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "def save_to_drive(model_path='models/transformer_gan.pt'):\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = '/content/drive/MyDrive/chopper_models/'\n",
    "    os.makedirs(drive_path, exist_ok=True)\n",
    "    \n",
    "    import shutil\n",
    "    dest_path = os.path.join(drive_path, os.path.basename(model_path))\n",
    "    shutil.copy(model_path, dest_path)\n",
    "    print(f\"Model saved to Google Drive at: {dest_path}\")\n",
    "\n",
    "# Uncomment to save to drive\n",
    "# save_to_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd4e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push changes back to GitHub (if you have permission)\n",
    "def push_to_github(commit_message=\"Updated model\"):\n",
    "    # Configure Git\n",
    "    !git config --global user.email \"your-email@example.com\"  # Replace with your email\n",
    "    !git config --global user.name \"Your Name\"  # Replace with your name\n",
    "    \n",
    "    # Add changes\n",
    "    !git add models/*.pt\n",
    "    \n",
    "    # Commit and push\n",
    "    !git commit -m \"{commit_message}\"\n",
    "    !git push origin master\n",
    "    \n",
    "    print(\"Changes pushed to GitHub\")\n",
    "\n",
    "# Uncomment to push changes\n",
    "# push_to_github(\"Updated transformer model with new drums\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
